{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tracktor_tf2_tutorial.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fEGq_3NxEKHS"
      },
      "source": [
        "# Multiple Object Tracking in TensorFlow 2 with Tracktor\n",
        "\n",
        "Tracktor is a simple but versatile object tracking architecture that leverages the power of deep learning-based object detection models to achieve near-SOTA results \"without bells and whistles\".\n",
        "\n",
        "Here, we showcase a minimum working implementation of Tracktor in TensorFlow 2 using the TensorFlow Object Detection library.\n",
        "\n",
        "Tracktor is due to [\"Tracking without bells and whistles\"](https://arxiv.org/abs/1903.05625) by Philipp Bergmann, Tim Meinhardt, and Laura Leal-Taixe (ICCV 2019), and the original PyTorch implementation is located [here](https://github.com/phil-bergmann/tracking_wo_bnw).\n",
        "\n",
        "We showcase Tracktor on [this video](https://mixkit.co/free-stock-video/little-girl-plays-with-her-dog-on-the-grass-14276/) from Mixkit.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "878dEpV3dkMm"
      },
      "source": [
        "## Installs and Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5LqdJ7qEpP_"
      },
      "source": [
        "import os\n",
        "import pathlib\n",
        "\n",
        "# Clones the tensorflow models repository if it doesn't already exist.\n",
        "if \"models\" in pathlib.Path.cwd().parts:\n",
        "  while \"models\" in pathlib.Path.cwd().parts:\n",
        "    os.chdir(\"..\")\n",
        "elif not pathlib.Path(\"models\").exists():\n",
        "  !git clone --depth 1 https://github.com/tensorflow/models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FfOQSp47EplA"
      },
      "source": [
        "# Installs the Object Detection API.\n",
        "%%bash\n",
        "cd models/research/\n",
        "protoc object_detection/protos/*.proto --python_out=.\n",
        "cp object_detection/packages/tf2/setup.py .\n",
        "python -m pip install ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzVzFDF-vMhk"
      },
      "source": [
        "from copy import deepcopy\n",
        "from glob import glob\n",
        "\n",
        "import imageio\n",
        "from IPython.display import display\n",
        "from IPython.display import Image as IPyImage\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from six import BytesIO\n",
        "import tensorflow as tf\n",
        "\n",
        "from object_detection.utils.config_util import get_configs_from_pipeline_file\n",
        "from object_detection.utils.label_map_util import create_category_index_from_labelmap\n",
        "from object_detection.utils.visualization_utils import visualize_boxes_and_labels_on_image_array as visualize\n",
        "from object_detection.builders import model_builder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MmaYXJJE7us"
      },
      "source": [
        "# Downloads pretrained Faster R-CNN model.\n",
        "%%bash\n",
        "wget http://download.tensorflow.org/models/object_detection/tf2/20200711/faster_rcnn_resnet152_v1_1024x1024_coco17_tpu-8.tar.gz\n",
        "tar -xzvf faster_rcnn_resnet152_v1_1024x1024_coco17_tpu-8.tar.gz\n",
        "mv faster_rcnn_resnet152_v1_1024x1024_coco17_tpu-8/checkpoint models/research/object_detection/test_data/\n",
        "rm faster_rcnn_resnet152_v1_1024x1024_coco17_tpu-8.tar.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQkAvWoBdzuU"
      },
      "source": [
        "## Load pretrained Faster R-CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQNfFOBXFetL"
      },
      "source": [
        "# Sets model variables.\n",
        "model_name = \"faster_rcnn_resnet152_v1_1024x1024_coco17_tpu-8\"\n",
        "data_dir = \"models/research/object_detection/test_data/\"\n",
        "model_dir = os.path.join(data_dir, \"checkpoint\")\n",
        "\n",
        "# Loads model configuration.\n",
        "pipeline_config = os.path.join(\"models/research/object_detection/configs/tf2/\",\n",
        "                                model_name + \".config\")\n",
        "configs = get_configs_from_pipeline_file(pipeline_config)\n",
        "model_config = configs[\"model\"]\n",
        "\n",
        "# Builds model (a Faster R-CNN Meta-Arch object) using config.\n",
        "model = model_builder.build(model_config=model_config, is_training=False)\n",
        "\n",
        "# Loads model checkpoint.\n",
        "ckpt = tf.train.Checkpoint(model=model)\n",
        "ckpt.restore(os.path.join(model_dir, \"ckpt-0\")).expect_partial()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUqwyX-wsq1S"
      },
      "source": [
        "# Loads category index using COCO label map.\n",
        "PATH_TO_LABELS = \"models/research/object_detection/data/mscoco_label_map.pbtxt\"\n",
        "category_index = create_category_index_from_labelmap(PATH_TO_LABELS,\n",
        "                                                     use_display_name=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_beqOnXjKaMn"
      },
      "source": [
        "# Defines a function to convert an image to a numpy array.\n",
        "def image_to_np(path):\n",
        "    image = Image.open(path)\n",
        "    width, height = image.size\n",
        "    image = image.resize((width // 2, height // 2))\n",
        "    image = np.array(image)\n",
        "    image = image.reshape((height // 2, width // 2, 3))\n",
        "    return image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bapEQGsuyzPo"
      },
      "source": [
        "# Downloads images from GCP.\n",
        "%%bash\n",
        "mkdir \"models/research/object_detection/test_images/tracktor_images\"\n",
        "cd \"models/research/object_detection/test_images/tracktor_images\"\n",
        "wget https://storage.googleapis.com/object-detection-dogfood/data/tracktor_images.tar.gz\n",
        "tar -xzvf \"tracktor_images.tar.gz\"\n",
        "rm \"tracktor_images.tar.gz\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZG47ReUM34Mu"
      },
      "source": [
        "# Converts input images to numpy.\n",
        "images = []\n",
        "image_paths = \"models/research/object_detection/test_images/tracktor_images/*.png\"\n",
        "for path in sorted(glob(image_paths)):\n",
        "    image = image_to_np(path)\n",
        "    images.append(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjUDVsvAgehy"
      },
      "source": [
        "# Defines Track class.\n",
        "class Track:\n",
        "    def __init__(self, id, box, cls, score):\n",
        "        self.id = id\n",
        "        self.box = box\n",
        "        self.cls = cls\n",
        "        self.score = score\n",
        "    def __repr__(self):\n",
        "        return str(self.id)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gw7i_VG8eVCp"
      },
      "source": [
        "## Object Detection and Tracking with Tracktor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6wF7wfJboFl"
      },
      "source": [
        "The basic concept of Tracktor is to repurpose the regression head of the object detection model to regress the previous frame's bounding boxes onto the current frame's features. This allows us to associate bounding boxes between frames without an additional tracking model (hence, \"without bells and whistles\").\n",
        "\n",
        "Our implementation does not include reidentification, as it often requires training a separate neural network (such as a Siamese network). Thus, we follow a 4-step process:\n",
        "\n",
        "\n",
        "1. Run detection using the Faster R-CNN.\n",
        "2. Regress previous-frame bounding boxes onto current-frame features; updates or removes tracks depending on regression confidence.\n",
        "3. Run non-maximum suppression to remove detection boxes which are already covered by tracks.\n",
        "4. Instantiate new tracks.\n",
        "\n",
        "Finally, it's worth noting the weakness of Tracktor: it requires a very good framerate to perform at its best, since the regression is most receptive to minute changes in the frame features. One can somewhat compensate for this weakness via a separate motion model, which we have not included here.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oF5tKQf-hKW2"
      },
      "source": [
        "# Sets threshold variables.\n",
        "# DET_CONF_THRESH is threshold to include a detection.\n",
        "# REG_CONF_THRESH is threshold to include a regression.\n",
        "# NMS_IOU_THRESH is threshold to remove boxes in NMS based on IOU.\n",
        "# NMS_SCORE_THRESH is threshold to remove boxes in NMS based on score.\n",
        "# LABEL_ID_OFFSET is the difference between 0 and the first class index.\n",
        "DET_CONF_THRESH = 0.8\n",
        "REG_CONF_THRESH = 0.15\n",
        "NMS_IOU_THRESH = 0.3\n",
        "NMS_SCORE_THRESH = 0.3\n",
        "LABEL_ID_OFFSET = 1\n",
        "\n",
        "tracks = []\n",
        "dead_tracks = []\n",
        "tracks_per_frame = []\n",
        "for num, image in enumerate(images):\n",
        "    print(f\"Frame {num + 1}/{len(images)}\")\n",
        "    # Converts numpy array to Tensor and adds batch dimension.\n",
        "    input_tensor = tf.convert_to_tensor(image, dtype=tf.float32)\n",
        "    input_tensor = tf.expand_dims(input_tensor, axis=0)\n",
        "\n",
        "    # Runs detection model on image.\n",
        "    inputs, true_shapes = model.preprocess(input_tensor)\n",
        "    pred = model.predict(inputs, true_shapes)\n",
        "    det = model.postprocess(pred, true_shapes)\n",
        "\n",
        "    # Extracts boxes, classes, and scores from detection output.\n",
        "    boxes = det[\"detection_boxes\"][0].numpy()\n",
        "    classes = det[\"detection_classes\"][0].numpy()\n",
        "    scores = det[\"detection_scores\"][0].numpy()\n",
        "\n",
        "    # Thresholds detection output.\n",
        "    keep = scores >= DET_CONF_THRESH\n",
        "    boxes = boxes[keep]\n",
        "    classes = classes[keep]\n",
        "    scores = scores[keep]\n",
        "\n",
        "    # Regresses previous frame tracks onto current frame features.\n",
        "    # This leverages the Faster R-CNN architecture to update track\n",
        "    # position without extra tracking \"bells and whistles\".\n",
        "    if tracks:\n",
        "        # Sets the current number of tracks.\n",
        "        num_proposals = len(tracks)\n",
        "\n",
        "        # Extracts features from detection.\n",
        "        feats = pred[\"rpn_features_to_crop\"]\n",
        "        preprocessed_shapes = pred[\"image_shape\"]\n",
        "\n",
        "        # Converts tracks to Tensor and pads to model.max_num_proposals.\n",
        "        # Note that if the detection model resizes the image, you will need\n",
        "        # to adjust the bounding box coordinates accordingly.\n",
        "        tracks_boxes = tf.convert_to_tensor([track.box for track in tracks],\n",
        "                                            dtype=tf.float32)\n",
        "        padding = ((0, model.max_num_proposals - num_proposals), (0, 0))\n",
        "        tracks_boxes = tf.pad(tracks_boxes, padding)\n",
        "        tracks_boxes = tf.expand_dims(tracks_boxes, axis=0)\n",
        "\n",
        "        # Runs box_prediction to regress boxes onto current features.\n",
        "        # Adds extra fields to the output and postprocesses.\n",
        "        box_pred = model._box_prediction(feats,\n",
        "                                         tracks_boxes,\n",
        "                                         preprocessed_shapes,\n",
        "                                         true_shapes)\n",
        "        box_pred[\"num_proposals\"] = tf.convert_to_tensor([num_proposals],\n",
        "                                                         dtype=tf.int32)\n",
        "        box_pred[\"rpn_features_to_crop\"] = feats\n",
        "        reg = model.postprocess(box_pred, true_shapes)\n",
        "\n",
        "        # Extracts boxes, classes, and scores from regression output.\n",
        "        reg_boxes = reg[\"detection_boxes\"][0].numpy()\n",
        "        reg_classes = reg[\"detection_classes\"][0].numpy()\n",
        "        reg_scores = reg[\"detection_scores\"][0].numpy()\n",
        "        indices = reg[\"detection_anchor_indices\"][0].numpy()\n",
        "\n",
        "        # Gets highest-confidence regression for each track.\n",
        "        tracks_to_update = set(range(num_proposals))\n",
        "        to_delete = []\n",
        "        while tracks_to_update:\n",
        "            for i, j in enumerate(indices):\n",
        "                if j in tracks_to_update:\n",
        "                    track = tracks[j]\n",
        "                    # If confidence is low, delete the track.\n",
        "                    if reg_scores[i] < REG_CONF_THRESH:\n",
        "                        to_delete.append(track)\n",
        "                    # If confidence is high, update the track.\n",
        "                    else:\n",
        "                        track.box = reg_boxes[i]\n",
        "                        track.cls = reg_classes[i]\n",
        "                        track.score = reg_scores[i]\n",
        "                    tracks_to_update.remove(j)\n",
        "\n",
        "            # If regression fails, delete the track.\n",
        "            for j in tracks_to_update:\n",
        "                to_delete.append(tracks[j])\n",
        "            break\n",
        "            \n",
        "        # Deletes tracks with no high-confidence regression in current frame.\n",
        "        for track in to_delete:\n",
        "            tracks.remove(track)\n",
        "            dead_tracks.append(track)\n",
        "    \n",
        "    # Filters boxes which are already covered by tracks.\n",
        "    if tracks and boxes.size != 0:\n",
        "        # Sets variables for non-maximum suppression (NMS).\n",
        "        # We let all the current tracks have a score of 2 so they are never\n",
        "        # removed. This will remove the boxes which most overlap with\n",
        "        # current tracks.\n",
        "        nms_boxes = np.concatenate((boxes, [track.box for track in tracks]))\n",
        "        nms_scores = np.concatenate((scores, [2. for track in tracks]))\n",
        "        max_output_size = len(nms_scores)\n",
        "\n",
        "        # Runs NMS to find which boxes to keep.\n",
        "        keep = tf.image.non_max_suppression(nms_boxes,\n",
        "                                            nms_scores,\n",
        "                                            max_output_size,\n",
        "                                            iou_threshold=NMS_IOU_THRESH,\n",
        "                                            score_threshold=NMS_SCORE_THRESH)\n",
        "        keep = keep.numpy()\n",
        "\n",
        "        # Finds which boxes to remove.\n",
        "        to_delete = []\n",
        "        for i, _ in enumerate(boxes):\n",
        "            if i not in keep:\n",
        "                to_delete.append(i)\n",
        "    \n",
        "        # Deletes boxes.\n",
        "        boxes = np.delete(boxes, to_delete, 0)\n",
        "        classes = np.delete(classes, to_delete)\n",
        "        scores = np.delete(scores, to_delete, 0)\n",
        "    \n",
        "    # Reidentification would go here.\n",
        "\n",
        "    # Instantiates new tracks.\n",
        "    for box, cls, score in zip(boxes, classes, scores):\n",
        "        id = len(tracks) + len(dead_tracks)\n",
        "        track = Track(id, box, cls, score)\n",
        "        tracks.append(track)\n",
        "\n",
        "    # Updates tracks_per_frame with this frame's results.\n",
        "    tracks_per_frame.append(deepcopy(tracks))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrkD-fcXea5B"
      },
      "source": [
        "## Visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPUO2QvETOOH"
      },
      "source": [
        "Failure cases are mostly due to using the pretrained weights without fine-tuning. There aren't many flying dogs in COCO-17!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mL7413jno4jh"
      },
      "source": [
        "vis_images = deepcopy(images)\n",
        "# Writes each image to disk with tracking boxes.\n",
        "for i, (tracks, vis_image) in enumerate(zip(tracks_per_frame, vis_images)):\n",
        "    # Gets tracking information for the image.\n",
        "    ids = np.array([track.id for track in tracks])\n",
        "    boxes = np.array([track.box for track in tracks])\n",
        "    classes = np.array([track.cls + LABEL_ID_OFFSET for track in tracks])\n",
        "    scores = np.array([track.score for track in tracks])\n",
        "\n",
        "    # Plots tracking boxes on the image.\n",
        "    visualize(\n",
        "        vis_image,\n",
        "        boxes,\n",
        "        classes,\n",
        "        scores,\n",
        "        category_index,\n",
        "        track_ids=ids,\n",
        "        min_score_thresh=REG_CONF_THRESH,\n",
        "        line_thickness=2,\n",
        "        use_normalized_coordinates=True)\n",
        "\n",
        "# Saves and displays results as a GIF.\n",
        "imageio.plugins.freeimage.download()\n",
        "gif_name = 'tracktor.gif'\n",
        "imageio.mimsave(gif_name, vis_images, 'GIF-FI', fps=15)\n",
        "display(IPyImage(open(gif_name, 'rb').read()))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}