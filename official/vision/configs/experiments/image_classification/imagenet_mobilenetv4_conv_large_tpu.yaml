# Top-1 Acc: 82.92% @ 500 epoches
runtime:
  distribution_strategy: 'tpu'
  mixed_precision_dtype: 'bfloat16'
task:
  model:
    num_classes: 1001
    input_size: [384, 384, 3]
    backbone:
      mobilenet:
        model_id: 'MobileNetV4ConvLarge'
        flat_stochastic_depth_drop_rate: true
        stochastic_depth_drop_rate: 0.2
      type: 'mobilenet'
    norm_activation:
      norm_epsilon: 0.001
      norm_momentum: 0.997
    dropout_rate: 0.2
  losses:
    l2_weight_decay: 0.0
    one_hot: false
    soft_labels: true
    label_smoothing: 0.1
  train_data:
    input_path: 'gs://mlcompass-data/imagenet/imagenet-2012-tfrecord/train*'
    is_training: true
    global_batch_size: 16384
    dtype: 'bfloat16'
    aug_type:
      randaug:
        cutout_const: 40
        exclude_ops: ['Cutout']
        magnitude: 15
      type: 'randaug'
    mixup_and_cutmix:
      cutmix_alpha: 1.0
      label_smoothing: 0.1
      mixup_alpha: 0.8
      prob: 0.2
      switch_prob: 0.5
  validation_data:
    input_path: 'gs://mlcompass-data/imagenet/imagenet-2012-tfrecord/valid*'
    is_training: false
    global_batch_size: 4096
    dtype: 'bfloat16'
    drop_remainder: false
trainer:
  train_steps: 39000  # 500 epochs
  validation_steps: 13
  validation_interval: 78
  steps_per_loop: 78  # NUM_EXAMPLES (1281167) // global_batch_size
  summary_interval: 78
  checkpoint_interval: 78
  max_to_keep: 1
  optimizer_config:
    learning_rate:
      cosine:
        decay_steps: 39000
        initial_learning_rate: 0.004
        name: 'CosineDecay'
      type: 'cosine'
    optimizer:
      adamw:
        exclude_from_weight_decay: ['batch_normalization']
        gradient_clip_norm: 0.0
        weight_decay_rate: 0.2
        name: 'AdamWeightDecay'
      type: 'adamw'
    warmup:
      linear:
        warmup_steps: 1560
        name: 'linear'
      type: 'linear'
