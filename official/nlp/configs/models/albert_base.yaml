task:
  model:
    encoder:
      type: albert
      albert:
        attention_dropout_rate: 0.0
        dropout_rate: 0.0
        hidden_activation: gelu
        hidden_size: 768
        initializer_range: 0.02
        intermediate_size: 3072
        max_position_embeddings: 512
        num_attention_heads: 12
        num_layers: 12
        type_vocab_size: 2
        vocab_size: 30000
